{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import sys\n",
    "import tensorflow as tf\n",
    "import tensorflow.python.platform\n",
    "from tensorflow.python.platform import gfile\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "from sklearn import cross_validation\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import av"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "path_to_video = 'test.mp4'\n",
    "path_to_frames = 'frames/'\n",
    "images_dir = path_to_frames\n",
    "model_dir = '../imagenet/classify_image_graph_def.pb'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def saliency_vector(features):\n",
    "    features = preprocessing.normalize(features, norm='l2')\n",
    "    feature_1 = np.vstack((np.zeros((1,features.shape[1])),features))\n",
    "    feature_2 = np.vstack((features,np.zeros((1,features.shape[1]))))\n",
    "    diff_vector = feature_2 - feature_1\n",
    "    return diff_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def frame_extractor(path_to_video,path_to_frames):\n",
    "    container = av.open(path_to_video)\n",
    "    video = next(s for s in container.streams if s.type == b'video')\n",
    "    for packet in container.demux(video):\n",
    "        for frame in packet.decode():\n",
    "            frame.to_image().save(path_to_frames+'/frame-%06d.jpg' % frame.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class ExtractFeatures:\n",
    "    def __init__(self,model_path,images_dir):\n",
    "        self.model = model_path\n",
    "        self.list_images = [images_dir+f for f in os.listdir(images_dir) if re.search('jpg|JPG', f)]\n",
    "        self.list_images.sort()\n",
    "    \n",
    "    def create_graph(self):\n",
    "        with gfile.FastGFile(self.model, 'rb') as f:\n",
    "            graph_def = tf.GraphDef()\n",
    "            graph_def.ParseFromString(f.read())\n",
    "            _ = tf.import_graph_def(graph_def, name='')\n",
    "    \n",
    "    def get_layer_list(self):\n",
    "        self.create_graph()\n",
    "        with tf.Session() as sess:\n",
    "            operation_list = sess.graph.get_operations()\n",
    "            for op in operation_list:\n",
    "                print op.name\n",
    "                print op.values().get_shape()\n",
    "\n",
    "    def extract_features(self,layer_name='pool_3:0',nb_features=2048):\n",
    "        features = np.empty((len(self.list_images),nb_features))\n",
    "        labels = []\n",
    "        self.create_graph()\n",
    "        with tf.Session() as sess:\n",
    "            next_to_last_tensor = sess.graph.get_tensor_by_name(layer_name)\n",
    "            for ind, image in enumerate(self.list_images):\n",
    "                #if (ind%100 == 0):\n",
    "                print('Processing %s...' % (image))\n",
    "                if not gfile.Exists(image):\n",
    "                    tf.logging.fatal('File does not exist %s', image)\n",
    "                    continue\n",
    "                image_data = gfile.FastGFile(image, 'rb').read()\n",
    "                predictions = sess.run(next_to_last_tensor,{'DecodeJpeg/contents:0': image_data})\n",
    "                features[ind,:] = np.squeeze(predictions)\n",
    "        return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing frames/frame-0000.jpg...\n",
      "Processing frames/frame-0001.jpg...\n",
      "Processing frames/frame-0002.jpg...\n",
      "Processing frames/frame-0169.jpg...\n",
      "Processing frames/frame-4091.jpg...\n",
      "Processing frames/frame-6695.jpg...\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    #frame_extractor(path_to_video,path_to_frames)\n",
    "    extract_features = ExtractFeatures(model_dir,images_dir)\n",
    "    extract_features.create_graph()\n",
    "    features = extract_features.extract_features()\n",
    "    pickle.dump(features, open('features', 'wb'))\n",
    "    diff_vector = saliency_vector(features)\n",
    "    pickle.dump(diff_vector, open('diff_vector','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7, 2048)\n"
     ]
    }
   ],
   "source": [
    "print diff_vector.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.0000000000000004, 0.1230300400139373, 0.036877493381364618, 0.99887036188231781, 0.93332663686498085, 0.48760886276019016, 0.99999999999999944]\n"
     ]
    }
   ],
   "source": [
    "distance = []\n",
    "for vector in diff_vector:\n",
    "    distance.append(np.linalg.norm(vector))\n",
    "print distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['frames/frame-0000.jpg', 'frames/frame-0001.jpg', 'frames/frame-0002.jpg', 'frames/frame-0169.jpg', 'frames/frame-4091.jpg', 'frames/frame-6695.jpg']\n"
     ]
    }
   ],
   "source": [
    "print extract_features.list_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
