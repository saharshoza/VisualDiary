{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import sys\n",
    "import tensorflow as tf\n",
    "import tensorflow.python.platform\n",
    "from tensorflow.python.platform import gfile\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "from sklearn import cross_validation\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import av"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "path_to_video = 'test.mp4'\n",
    "path_to_frames = 'frames/'\n",
    "images_dir = path_to_frames\n",
    "model_dir = '../imagenet/classify_image_graph_def.pb'\n",
    "results_dir = '../results/'\n",
    "features_file = os.path.join(results_dir, 'features')\n",
    "saliency_matrix_file = os.path.join(results_dir, 'saliency_matrix')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def frame_extractor(path_to_video, path_to_frames):\n",
    "    container = av.open(path_to_video)\n",
    "    video = next(s for s in container.streams if s.type == b'video')\n",
    "    for packet in container.demux(video):\n",
    "        for frame in packet.decode():\n",
    "            frame.to_image().save(path_to_frames + '/frame-%06d.jpg' % frame.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class FeatureProcessor:\n",
    "    def __init__(self, model_path, images_dir, sampling_rate=10, saliency_threshold=0.8):\n",
    "        self.model_path = model_path\n",
    "        self.images_path = sorted([images_dir + f for f in os.listdir(images_dir) if re.search('jpg|JPG', f)])\n",
    "        self.sampling_rate = sampling_rate\n",
    "        self.saliency_threshold = saliency_threshold\n",
    "        \n",
    "    def create_graph(self):\n",
    "        with gfile.FastGFile(self.model_path, 'rb') as f:\n",
    "            graph_def = tf.GraphDef()\n",
    "            graph_def.ParseFromString(f.read())\n",
    "            _ = tf.import_graph_def(graph_def, name='')\n",
    "    \n",
    "    def get_layer_list(self):\n",
    "        self.create_graph()\n",
    "        with tf.Session() as sess:\n",
    "            operation_list = sess.graph.get_operations()\n",
    "            for op in operation_list:\n",
    "                print op.name\n",
    "                print op.values().get_shape()\n",
    "\n",
    "    # TODO : Experiment with other layers.            \n",
    "    def extract_features(self, layer_name='pool_3:0', nb_features=2048):\n",
    "        features = np.empty((len(self.images_path),nb_features))\n",
    "        labels = []\n",
    "        self.create_graph()\n",
    "        with tf.Session() as sess:\n",
    "            next_to_last_tensor = sess.graph.get_tensor_by_name(layer_name)\n",
    "            for index, image in enumerate(self.images_path):\n",
    "                if (index % self.sampling_rate == 0):\n",
    "                    print('Processing %s...' % (image))\n",
    "                    if not gfile.Exists(image):\n",
    "                        tf.logging.fatal('File does not exist %s', image)\n",
    "                        continue\n",
    "                    image_data = gfile.FastGFile(image, 'rb').read()\n",
    "                    predictions = sess.run(next_to_last_tensor, {'DecodeJpeg/contents:0': image_data})\n",
    "                    features[index, :] = np.squeeze(predictions)\n",
    "        return features\n",
    "    \n",
    "    def compute_change_points(self, features):\n",
    "        features = preprocessing.normalize(features, norm='l2')\n",
    "        features_1 = np.vstack((np.zeros((1, features.shape[1])), features))\n",
    "        features_2 = np.vstack((features,np.zeros((1, features.shape[1]))))\n",
    "        saliency_matrix = features_2 - features_1\n",
    "        \n",
    "        distance = []\n",
    "        for vector in saliency_matrix:\n",
    "            distance.append(np.linalg.norm(vector))\n",
    "        print distance\n",
    "        distance = np.asarray(distance)\n",
    "        \n",
    "        change_points = (np.where(distance > self.saliency_threshold)) * self.sampling_rate\n",
    "        return change_points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing frames/frame-000000.jpg...\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    frame_extractor(path_to_video, path_to_frames)\n",
    "    feature_processor = FeatureProcessor(model_dir, images_dir)\n",
    "    feature_processor.create_graph()\n",
    "    features = feature_processor.extract_features()\n",
    "    change_points = feature_processor.compute_change_points(features)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
